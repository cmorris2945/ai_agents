{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae02158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OpenAi Key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description= \"Primary affiliation of the analyst\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the analyst\"\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the analyst in the context of the topic\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description = \"Description of the analyst focusm concerns, and motives\",\n",
    "\n",
    "    )\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "    \n",
    "class Perspectives(BaseModel):\n",
    "    analysts: List[Analyst] = Field(\n",
    "        description=\"Comprehensive list of analysts with their roles and affiliations\",\n",
    "    )\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analysts_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd1a762",
   "metadata": {},
   "source": [
    "BUILDING THE AI ANALYST SUB GRAPH....   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analysts personas. Follow these\n",
    "instructions carefully 'dusthead': \n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "\n",
    "2. Examine any editorial feedback that has been optimally provided to guide creation of the analysts:\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "\n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one anlyst to each theme.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "\n",
    "    \"\"\"Create Analysts...\"\"\"\n",
    "\n",
    "    topic= state['topic']\n",
    "    max_analysts=state[\"max_analysts\"]\n",
    "    human_analysts_feedback= state.get(\"human_analysts_feedback\", \"\")\n",
    "\n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_message = analyst_instructions.format(topic=topic,\n",
    "                                                 human_analysts_feedback=human_analysts_feedback,\n",
    "                                                 max_analysts=max_analysts)\n",
    "    analysts = structured_llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=\"Generate the set of analysts\")])\n",
    "\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "def human_feedback(state:GenerateAnalystState):\n",
    "    \"\"\"No-op node that should be interrupted on \"\"\"\n",
    "    pass\n",
    "\n",
    "def should_continue(state:GenerateAnalystsState):\n",
    "    \"\"\"Return the next node to execute\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", None)\n",
    "\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    \n",
    "\n",
    "    return END\n",
    "\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", should_continue, [\"create_analysts\", END])\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f943ff6",
   "metadata": {},
   "source": [
    "RUNNING SUB GRAPH WITH EXAMPLE TO SEE IF IT WORKS...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 3\n",
    "topic= \"The benefits of adopting LangGraph as an agent framework\"\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in graph.stream({\"topic\":topic, \"max_analysts\": max,}, thread, stream_mode=\"values\"):\n",
    "\n",
    "    analysts = event.get(\"analysts\", \"\")\n",
    "\n",
    "    if analysts:\n",
    "        for anlyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\"* 50)\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa606be",
   "metadata": {},
   "source": [
    "HUMAN FEEDBACK EXAMPLE...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code is getting the current state of the node....\n",
    "state= graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64d35b",
   "metadata": {},
   "source": [
    "HERE I WILL ALLOW \"HUMAN FEEDBACK\". IN CASE THE USER DOES NOT LIKE THE RESULTS GENERATED...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.update_state(thread, {\"human_analyst_feedback\":\n",
    "                            \"Add in someone from a startup to add an entrepreneur of sorts.\"}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c3e9d",
   "metadata": {},
   "source": [
    "FEEDBACK GIVEN. LETS NOW CONTINUE WITH THE EXECUTION OF THE APPLICATION...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "\n",
    "    analysts= event.get(\"analysts\", \"\")\n",
    "    if analysts:\n",
    "        for analyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25ef46a",
   "metadata": {},
   "source": [
    "If I am satisfied with the new analysts provided. I will provide no additional human feedback so the app can continue the execution with 3 of the analysts. To do that, I set \"further_feedback\" to \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "further_feedback = None\n",
    "graph.update_state(thread, {\"human_analyst_feedback\":\n",
    "                    further_feedback}, as_node=\"human_feedback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No more human feedback. Continue excution of agent flow....\n",
    "\n",
    "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
    "    print(\"--Node--\")\n",
    "    node_name= next(iter(event.keys()))\n",
    "    print(node_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14cf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "analysts = final_state.values.get(\"analysts\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d56f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c40503",
   "metadata": {},
   "outputs": [],
   "source": [
    "for analyst in analysts:\n",
    "    print(f\"Name: {analyst.name}\")\n",
    "    print(f\"Affiliation: {analyst.affiliation}\")\n",
    "    print(f\"Role: {analyst.role}\")\n",
    "    print(f\"Description: {analyst.desription}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b7653f",
   "metadata": {},
   "source": [
    "SECOND SUB GRAPH THE \"INTERVIEW GENERATOR\"  SUB GRAPH...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class InterviewState(MessagesState):\n",
    "    max_num_turns = int\n",
    "    context: Annotated[List, operator.add]\n",
    "    analyst: Analyst\n",
    "    interview: str\n",
    "    sections: list\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = False(None, description= \"Search query for retrieval.\")\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229276c7",
   "metadata": {},
   "source": [
    "Define the noDe generate_question...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc92606",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic. \n",
    "\n",
    "Your goal is boil down to interesting and specific insights related to your topic.\n",
    "\n",
    "1. Interesting: Insights that people will find surprising or non-obvious.\n",
    "        \n",
    "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
    "\n",
    "Here is your topic of focus and set of goals: {goals}\n",
    "        \n",
    "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
    "\n",
    "Continue to ask questions to drill down and refine your understanding of the topic.\n",
    "        \n",
    "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
    "\n",
    "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
    "\n",
    "\n",
    "def generate_questions(state: InterviewState):\n",
    "    \"\"\"Node to generate a question\"\"\"\n",
    "\n",
    "    ## get the state....\n",
    "    analyst = state[\"analyst\"]\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "\n",
    "    ## generate questions...\n",
    "\n",
    "    system_message = question_instructions.format(goals=analyst.persona)\n",
    "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
    "\n",
    "    ## Write messages to state\n",
    "\n",
    "    return {\"messages\": [question]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3797ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6c993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e5d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863bb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a420c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d9e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e9279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf2c54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd580e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
