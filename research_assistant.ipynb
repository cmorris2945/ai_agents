{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae02158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OpenAi Key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Analyst(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description= \"Primary affiliation of the analyst\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the analyst\"\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the analyst in the context of the topic\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description = \"Description of the analyst focusm concerns, and motives\",\n",
    "\n",
    "    )\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "    \n",
    "class Perspectives(BaseModel):\n",
    "    analysts: List[Analyst] = Field(\n",
    "        description=\"Comprehensive list of analysts with their roles and affiliations\",\n",
    "    )\n",
    "class GenerateAnalystsState(TypedDict):\n",
    "    topic: str\n",
    "    max_analysts: int\n",
    "    human_analysts_feedback: str\n",
    "    analysts: List[Analyst]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd1a762",
   "metadata": {},
   "source": [
    "BUILDING THE AI ANALYST SUB GRAPH....   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "analyst_instructions = \"\"\"You are tasked with creating a set of AI analysts personas. Follow these\n",
    "instructions carefully 'dusthead': \n",
    "\n",
    "1. First, review the research topic:\n",
    "{topic}\n",
    "\n",
    "2. Examine any editorial feedback that has been optimally provided to guide creation of the analysts:\n",
    "{human_analyst_feedback}\n",
    "\n",
    "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
    "\n",
    "4. Pick the top {max_analysts} themes.\n",
    "\n",
    "5. Assign one anlyst to each theme.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_analysts(state: GenerateAnalystsState):\n",
    "\n",
    "    \"\"\"Create Analysts...\"\"\"\n",
    "\n",
    "    topic= state['topic']\n",
    "    max_analysts=state[\"max_analysts\"]\n",
    "    human_analysts_feedback= state.get(\"human_analysts_feedback\", \"\")\n",
    "\n",
    "    structured_llm = llm.with_structured_output(Perspectives)\n",
    "\n",
    "    system_message = analyst_instructions.format(topic=topic,\n",
    "                                                 human_analysts_feedback=human_analysts_feedback,\n",
    "                                                 max_analysts=max_analysts)\n",
    "    analysts = structured_llm.invoke([SystemMessage(content=system_message)] + [HumanMessage(content=\"Generate the set of analysts\")])\n",
    "\n",
    "    return {\"analysts\": analysts.analysts}\n",
    "\n",
    "def human_feedback(state:GenerateAnalystState):\n",
    "    \"\"\"No-op node that should be interrupted on \"\"\"\n",
    "    pass\n",
    "\n",
    "def should_continue(state:GenerateAnalystsState):\n",
    "    \"\"\"Return the next node to execute\"\"\"\n",
    "\n",
    "    human_analyst_feedback = state.get(\"human_analyst_feedback\", None)\n",
    "\n",
    "    if human_analyst_feedback:\n",
    "        return \"create_analysts\"\n",
    "    \n",
    "\n",
    "    return END\n",
    "\n",
    "builder = StateGraph(GenerateAnalystsState)\n",
    "\n",
    "builder.add_node(\"create_analysts\", create_analysts)\n",
    "builder.add_node(\"human_feedback\", human_feedback)\n",
    "\n",
    "builder.add_edge(START, \"create_analysts\")\n",
    "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
    "builder.add_conditional_edges(\"human_feedback\", should_continue, [\"create_analysts\", END])\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(interrupt_before=[\"human_feedback\"], checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f943ff6",
   "metadata": {},
   "source": [
    "RUNNING SUB GRAPH WITH EXAMPLE TO SEE IF IT WORKS...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_analysts = 3\n",
    "topic= \"The benefits of adopting LangGraph as an agent framework\"\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in graph.stream({\"topic\":topic, \"max_analysts\": max,}, thread, stream_mode=\"values\"):\n",
    "\n",
    "    analysts = event.get(\"analysts\", \"\")\n",
    "\n",
    "    if analysts:\n",
    "        for anlyst in analysts:\n",
    "            print(f\"Name: {analyst.name}\")\n",
    "            print(f\"Affiliation: {analyst.affiliation}\")\n",
    "            print(f\"Role: {analyst.role}\")\n",
    "            print(f\"Description: {analyst.description}\")\n",
    "            print(\"-\"* 50)\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa606be",
   "metadata": {},
   "source": [
    "HUMAN FEEDBAK EXAMPLE...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "state= graph.get_state(thread)\n",
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53b24b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb0c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b97e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14cf3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d56f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c40503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd5e595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc92606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3797ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e6c993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
