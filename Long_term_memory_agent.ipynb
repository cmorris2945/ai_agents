{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cbecde",
   "metadata": {},
   "source": [
    "# Agent with Long-Time Memory\n",
    "* We will build an Agent that will help us to **manage a ToDo list**.\n",
    "* It will decide:\n",
    "    * **when to save items** to our ToDo list.\n",
    "    * **to save either a user profile or a collection of ToDo items**.\n",
    "* In addition to semantic memory (user facts), it will also have **procedural memory**.\n",
    "    * Remember, the procedural memory is the system prompt. This will allow the user to set preferences for creating ToDo items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2f374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3912161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ.get(\"Open_ai_key_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54628e3",
   "metadata": {},
   "source": [
    "Lets install Langchain here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenA\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8cb60",
   "metadata": {},
   "source": [
    "Using TrustCall here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70611337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    conent: str = Field(description= \"The main content of the memory. For example:\" \\\n",
    "    \"User expressed interest in learning about French language...\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## Everytime you make instance of this class, you make a new list of tools used...\n",
    "\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        ### This is here will collect information about the tools used in the extractor...\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                    \n",
    "                )\n",
    "spy = Spy()\n",
    "\n",
    "##Initialize the model here....\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "## create the extractor here....\n",
    "\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice= \"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "### Add the spy as a listener to the extractor....\n",
    "\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78efecb",
   "metadata": {},
   "source": [
    "## Running Trustcall without \"listener\" to monitor the workflow tool call..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "## Instruction to the model to extract the memories from the user input...\n",
    "instruction = \"\"\"Extract memmories from the following converstion 'Mac'...\"\"\"\n",
    "\n",
    "### Converstion here....\n",
    "conversation =[HumanMessage(content=\"Hi I'm Chris\"),\n",
    "               AIMessage(content= \"Nice to meet you 'Jackass'\"),\n",
    "               HumanMessage(content=\"Yesterday I visited the museum of History\")]\n",
    "\n",
    "### Using the regular extractor here without the listener....\n",
    "result = trustcall_extractor.invoke(\"messages\": [SystemMessage(content= instruction)] + conversation})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Messages that contain tool calls....\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffa29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bd9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467fbd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6b1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd18a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd7493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
