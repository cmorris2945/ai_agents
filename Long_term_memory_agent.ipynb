{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76cbecde",
   "metadata": {},
   "source": [
    "# Agent with Long-Time Memory\n",
    "* We will build an Agent that will help us to **manage a ToDo list**.\n",
    "* It will decide:\n",
    "    * **when to save items** to our ToDo list.\n",
    "    * **to save either a user profile or a collection of ToDo items**.\n",
    "* In addition to semantic memory (user facts), it will also have **procedural memory**.\n",
    "    * Remember, the procedural memory is the system prompt. This will allow the user to set preferences for creating ToDo items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2f374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f124bc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3912161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ.get(\"Open_ai_key_here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54628e3",
   "metadata": {},
   "source": [
    "Lets install Langchain here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700d2831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenA\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c8cb60",
   "metadata": {},
   "source": [
    "Using TrustCall here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70611337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    conent: str = Field(description= \"The main content of the memory. For example:\" \\\n",
    "    \"User expressed interest in learning about French language...\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "## Everytime you make instance of this class, you make a new list of tools used...\n",
    "\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        ### This is here will collect information about the tools used in the extractor...\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                    \n",
    "                )\n",
    "spy = Spy()\n",
    "\n",
    "##Initialize the model here....\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "## create the extractor here....\n",
    "\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice= \"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "### Add the spy as a listener to the extractor....\n",
    "\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78efecb",
   "metadata": {},
   "source": [
    "## Running Trustcall without \"listener\" to monitor the workflow tool call Just to test Trustcall..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51fc40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "## Instruction to the model to extract the memories from the user input...\n",
    "instruction = \"\"\"Extract memmories from the following converstion 'Mac'...\"\"\"\n",
    "\n",
    "### Converstion here....\n",
    "conversation =[HumanMessage(content=\"Hi I'm Chris\"),\n",
    "               AIMessage(content= \"Nice to meet you 'Jackass'\"),\n",
    "               HumanMessage(content=\"Yesterday I visited the local state prison to make fun of all the prisoners...\")]\n",
    "\n",
    "### Using the regular extractor here without the listener....\n",
    "result = trustcall_extractor.invoke(\"messages\": [SystemMessage(content= instruction)] + conversation})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Messages that contain tool calls....\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ffa29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Responses contain the memories that adhere to the schema....\n",
    "\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Metadata contains the tool calls used in the extraction process...\n",
    "\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4467fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update the conversation here...\n",
    "\n",
    "updated_conversation = [AIMessage(content=\"Thats great. what did you do after?\"),\n",
    "                        HumanMessage(content=\"I went to Tiburon and prepared a paella in the park\"),\n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about finally learning to cook paella for \" \\\n",
    "                        \"the sake of my girlfriend.\"),]\n",
    "\n",
    "## Update the  instruction here...\n",
    "\n",
    "system_instruction = \"\"\"Update existing memories and create new ones BASES on the followinf converstaion: \"\"\"\n",
    "\n",
    "\n",
    "## We'll save the existing memories, giving them an ID, key (tool name), and value....\n",
    "\n",
    "tool_name = \"Memory\"\n",
    "existing_memories= [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803d9382",
   "metadata": {},
   "source": [
    "## And now let's see Trustcall with the listener..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0c8305",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now here, we will use the extractor with the listener now.\n",
    "## We will envoke the extractor with the updated conversation and existing memories...\n",
    "\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation,\n",
    "                                                        \"existing\": existing_memories})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Metadata contains the tool call....\n",
    "\n",
    "for m in result[\"response_metadata\"]:\n",
    "    print(m)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034c3f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Messages ccontain the tool calls here...\n",
    "\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83330b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parsed responses....\n",
    "\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4f36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inspet the tool calls made by the \"Trustcall\" extractor....\n",
    "\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b73670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "475783e8",
   "metadata": {},
   "source": [
    "## Ok, now in this section I will create the \"UpdateMemory\" class to select the element in the long-term memory we will update at one particular moment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first import the \"TypedDict\" and the \"Literal\" classes from the \"typing\" module....\n",
    "from typing import TypedDict, Literal\n",
    "## make the UpdateMemory class and pass TypedDict as the base class...\n",
    "\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\"Decision on what memory type to update.\"\"\"\n",
    "    update_type:Literal[\"user\", \"todo\", \"instructions\"]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb725ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b28633bf",
   "metadata": {},
   "source": [
    "## Now I will build the actual agent\n",
    "\n",
    "* I will use the router \"route_message\" to make a binary decision to save memories.\n",
    "* The memory collection updating will be handled by \"Trustcall\" in the write_memory node, like I did previously...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b770b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3b3a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b9cc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf6b1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccd18a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd7493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
